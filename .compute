#!/bin/bash

set -xe

# Expected file structure (from .install):
#
# ../tmp/native_client/
#      *
# ../keep/
#      source_model/
#          checkpoint
#          model.meta
#          model.data
#          model.index
#
# Created by filter_train_dev_test.py (this script)
#
# ../keep/
#     target_lang/
#         valid_dev.csv
#         valid_test.csv
#         valid_train.csv
#
# Created by DeepSpeech.py (this script):
#
# ../keep/
#     target_lang/
#         source_model/
#             run/
#               RESULTS.json
#               summaries/
#               model/
#               ckpt/
#


source ../tmp/venv/bin/activate

# train from scratch with num_layers_dropped=6
target_lang='all'
source_model='en-v030'


input_dir="/snakepit/shared/data/mozilla/CommonVoice/v2.0-alpha2.0"
#input_dir="/home/josh/Downloads/CV"
data="../keep/${target_lang}"
mkdir $data


python3 filter_train_dev_test.py "${input_dir}" "${target_lang}" "${input_dir}/clips.tsv" "${data}"
python3 util/check_characters.py "${data}/*.csv"




# ###              ###
# ### FROM SCRATCH ###
# ###              ###


# echo "##############################"
# echo "STARTING TRAINING FROM SCRATCH"
# echo "##############################"

# exp="../keep/${target_lang}/scratch/"

# python3 -u DeepSpeech.py \
# 	    --export_dir "${exp}/model/" \
# 	    --summary_dir "${exp}/summaries/" \
# 	    --checkpoint_dir "${exp}/ckpt/" \
# 	    --test_output_file "${exp}/RESULTS.json" \
# 	    --train_files "${data}/valid_train.csv"\
# 	    --dev_files "${data}/valid_dev.csv" \
# 	    --test_files "${data}/valid_test.csv" \
# 	    --n_hidden 2048 \
# 	    --epoch 1000 \
#         --earlystop_nsteps 5 \
# 	    --train_batch_size 24 \
# 	    --dev_batch_size 48 \
# 	    --test_batch_size 48 \
# 	    --learning_rate 0.0001 \
# 	    --dropout_rate 0.2 \
# 	    --display_step 0 \
# 	    --validation_step 1 \
#         --summary_secs 60 \
# 	    --decoder_library_path "../tmp/native_client/libctc_decoder_with_kenlm.so"



###                   ###
### TRANSFER LEARNING ###
###                   ###


# if [ $num_layers_dropped -lt 6 ]; then
for num_layers_dropped in 1 2 3 4 5; do

    echo "##########################"
    echo "STARTING TRANSFER LEARNING W/ FROZEN"
    echo " num_layers_dropped=${num_layers_dropped}"
    echo "##########################"
    
    exp="../keep/${target_lang}/frozen/${num_layers_dropped}"

    CUDA_VISIBLE_DEVICES="0" \
    python3 -u DeepSpeech.py \
	        --export_dir "${exp}/model/" \
	        --summary_dir "${exp}/summaries/" \
	        --checkpoint_dir "${exp}/ckpt/" \
	        --test_output_file "${exp}/RESULTS.json" \
	        --drop_source_layers "${num_layers_dropped}" \
	        --source_model_checkpoint_dir "../keep/${source_model}" \
	        --train_files "${data}/shared_train.csv"\
            --train_nonspeech "../keep/urbansound8k/Train/train_ds.csv" \
            --dev_files "${data}/shared_dev.csv" \
            --dev_nonspeech "../keep/urbansound8k/Train/dev_ds.csv" \
	        --test_files "${data}/valid_test.csv" \
            --notest \
	        --n_hidden 2048 \
	        --epoch -1 \
            --noearly_stop \
	        --train_batch_size 24 \
	        --dev_batch_size 48 \
	        --test_batch_size 48 \
	        --learning_rate 0.0001 \
	        --dropout_rate 0.2 \
	        --display_step 0 \
	        --validation_step 1 \
            --summary_secs 60
done





echo "$0: END"
